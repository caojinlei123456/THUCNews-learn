{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E://cnews/cnews.vocab.txt', encoding='utf8') as file:\n",
    "    vocabulary_list = [k.strip() for k in file.readlines()]\n",
    "#读取词表\n",
    "with open('E://cnews/cnews.train.txt', encoding='utf8') as file:\n",
    "    line_list = [k.strip() for k in file.readlines()]\n",
    "    #读取每行\n",
    "    train_label_list = [k.split()[0] for k in line_list]\n",
    "    #将标签依次取出\n",
    "    train_content_list = [k.split(maxsplit=1)[1] for k in line_list]\n",
    "    #将内容依次取出,此处注意split()选择最大分割次数为1,否则句子被打断.\n",
    "#同理读取test数据\n",
    "with open('E://cnews/cnews.test.txt', encoding='utf8') as file:\n",
    "    line_list = [k.strip() for k in file.readlines()]\n",
    "    test_label_list = [k.split()[0] for k in line_list]\n",
    "    test_content_list = [k.split(maxsplit=1)[1] for k in line_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_dict = dict(((b, a) for a, b in enumerate(vocabulary_list)))\n",
    "def content2vector(content_list):\n",
    "    content_vector_list = []\n",
    "    for content in content_list:\n",
    "        content_vector = []\n",
    "        for word in content:\n",
    "            if word in word2id_dict:\n",
    "                content_vector.append(word2id_dict[word])\n",
    "            else:\n",
    "                content_vector.append(word2id_dict['<PAD>'])\n",
    "        content_vector_list.append(content_vector)\n",
    "    return content_vector_list\n",
    "train_vector_list = content2vector(train_content_list)\n",
    "test_vector_list = content2vector(test_content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[387,\n",
       " 1197,\n",
       " 2173,\n",
       " 215,\n",
       " 110,\n",
       " 264,\n",
       " 814,\n",
       " 219,\n",
       " 16,\n",
       " 725,\n",
       " 981,\n",
       " 2629,\n",
       " 0,\n",
       " 245,\n",
       " 1645,\n",
       " 14,\n",
       " 1190,\n",
       " 231,\n",
       " 110,\n",
       " 808,\n",
       " 2026,\n",
       " 2784,\n",
       " 43,\n",
       " 581,\n",
       " 224,\n",
       " 98,\n",
       " 2345,\n",
       " 470,\n",
       " 1190,\n",
       " 1609,\n",
       " 659,\n",
       " 188,\n",
       " 209,\n",
       " 0,\n",
       " 34,\n",
       " 32,\n",
       " 1609,\n",
       " 659,\n",
       " 1,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 716,\n",
       " 153,\n",
       " 165,\n",
       " 8,\n",
       " 1309,\n",
       " 1362,\n",
       " 1190,\n",
       " 298,\n",
       " 2,\n",
       " 1061,\n",
       " 1478,\n",
       " 3,\n",
       " 105,\n",
       " 70,\n",
       " 49,\n",
       " 12,\n",
       " 62,\n",
       " 61,\n",
       " 951,\n",
       " 91,\n",
       " 164,\n",
       " 1,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 2,\n",
       " 62,\n",
       " 234,\n",
       " 977,\n",
       " 851,\n",
       " 333,\n",
       " 144,\n",
       " 264,\n",
       " 32,\n",
       " 14,\n",
       " 1190,\n",
       " 2,\n",
       " 900,\n",
       " 1478,\n",
       " 1,\n",
       " 245,\n",
       " 1645,\n",
       " 100,\n",
       " 61,\n",
       " 244,\n",
       " 200,\n",
       " 40,\n",
       " 183,\n",
       " 1181,\n",
       " 1243,\n",
       " 10,\n",
       " 18,\n",
       " 55,\n",
       " 52,\n",
       " 883,\n",
       " 56,\n",
       " 1191,\n",
       " 1191,\n",
       " 246,\n",
       " 57,\n",
       " 3,\n",
       " 49,\n",
       " 12,\n",
       " 62,\n",
       " 20,\n",
       " 951,\n",
       " 12,\n",
       " 7,\n",
       " 164,\n",
       " 1,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 6,\n",
       " 725,\n",
       " 134,\n",
       " 11,\n",
       " 169,\n",
       " 110,\n",
       " 57,\n",
       " 977,\n",
       " 851,\n",
       " 2,\n",
       " 27,\n",
       " 475,\n",
       " 1,\n",
       " 125,\n",
       " 56,\n",
       " 5,\n",
       " 1675,\n",
       " 1327,\n",
       " 1327,\n",
       " 2,\n",
       " 1,\n",
       " 405,\n",
       " 554,\n",
       " 468,\n",
       " 188,\n",
       " 336,\n",
       " 185,\n",
       " 143,\n",
       " 125,\n",
       " 61,\n",
       " 951,\n",
       " 1609,\n",
       " 659,\n",
       " 56,\n",
       " 8,\n",
       " 14,\n",
       " 1190,\n",
       " 1,\n",
       " 108,\n",
       " 1135,\n",
       " 121,\n",
       " 244,\n",
       " 1564,\n",
       " 20,\n",
       " 951,\n",
       " 2,\n",
       " 977,\n",
       " 851,\n",
       " 194,\n",
       " 165,\n",
       " 8,\n",
       " 264,\n",
       " 32,\n",
       " 330,\n",
       " 464,\n",
       " 900,\n",
       " 1478,\n",
       " 3,\n",
       " 61,\n",
       " 951,\n",
       " 91,\n",
       " 164,\n",
       " 1,\n",
       " 143,\n",
       " 157,\n",
       " 244,\n",
       " 1296,\n",
       " 271,\n",
       " 977,\n",
       " 851,\n",
       " 57,\n",
       " 27,\n",
       " 1,\n",
       " 14,\n",
       " 1190,\n",
       " 167,\n",
       " 63,\n",
       " 61,\n",
       " 10,\n",
       " 385,\n",
       " 22,\n",
       " 122,\n",
       " 27,\n",
       " 1,\n",
       " 80,\n",
       " 505,\n",
       " 1055,\n",
       " 1342,\n",
       " 165,\n",
       " 8,\n",
       " 886,\n",
       " 61,\n",
       " 34,\n",
       " 2,\n",
       " 215,\n",
       " 730,\n",
       " 3,\n",
       " 1551,\n",
       " 205,\n",
       " 538,\n",
       " 4,\n",
       " 538,\n",
       " 2,\n",
       " 608,\n",
       " 144,\n",
       " 1,\n",
       " 157,\n",
       " 244,\n",
       " 72,\n",
       " 404,\n",
       " 10,\n",
       " 143,\n",
       " 125,\n",
       " 61,\n",
       " 951,\n",
       " 2,\n",
       " 644,\n",
       " 36,\n",
       " 977,\n",
       " 851,\n",
       " 1,\n",
       " 18,\n",
       " 55,\n",
       " 52,\n",
       " 883,\n",
       " 66,\n",
       " 202,\n",
       " 10,\n",
       " 1,\n",
       " 125,\n",
       " 405,\n",
       " 165,\n",
       " 8,\n",
       " 330,\n",
       " 464,\n",
       " 490,\n",
       " 121,\n",
       " 2,\n",
       " 1278,\n",
       " 554,\n",
       " 1,\n",
       " 21,\n",
       " 10,\n",
       " 232,\n",
       " 797,\n",
       " 157,\n",
       " 200,\n",
       " 40,\n",
       " 1,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 526,\n",
       " 126,\n",
       " 11,\n",
       " 853,\n",
       " 143,\n",
       " 125,\n",
       " 2,\n",
       " 977,\n",
       " 851,\n",
       " 1,\n",
       " 117,\n",
       " 244,\n",
       " 371,\n",
       " 534,\n",
       " 1404,\n",
       " 267,\n",
       " 1070,\n",
       " 832,\n",
       " 3,\n",
       " 6,\n",
       " 1190,\n",
       " 11,\n",
       " 977,\n",
       " 851,\n",
       " 39,\n",
       " 589,\n",
       " 157,\n",
       " 244,\n",
       " 34,\n",
       " 84,\n",
       " 194,\n",
       " 9,\n",
       " 5,\n",
       " 421,\n",
       " 217,\n",
       " 1712,\n",
       " 1993,\n",
       " 182,\n",
       " 1,\n",
       " 108,\n",
       " 6,\n",
       " 725,\n",
       " 492,\n",
       " 35,\n",
       " 534,\n",
       " 86,\n",
       " 72,\n",
       " 404,\n",
       " 100,\n",
       " 65,\n",
       " 1,\n",
       " 117,\n",
       " 244,\n",
       " 326,\n",
       " 68,\n",
       " 23,\n",
       " 1950,\n",
       " 1052,\n",
       " 24,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 1609,\n",
       " 659,\n",
       " 71,\n",
       " 59,\n",
       " 4,\n",
       " 309,\n",
       " 2,\n",
       " 977,\n",
       " 851,\n",
       " 1,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 321,\n",
       " 332,\n",
       " 41,\n",
       " 232,\n",
       " 297,\n",
       " 54,\n",
       " 8,\n",
       " 2,\n",
       " 157,\n",
       " 200,\n",
       " 9,\n",
       " 333,\n",
       " 33,\n",
       " 54,\n",
       " 215,\n",
       " 110,\n",
       " 2,\n",
       " 814,\n",
       " 931,\n",
       " 162,\n",
       " 477,\n",
       " 31,\n",
       " 831,\n",
       " 120,\n",
       " 593,\n",
       " 247,\n",
       " 253,\n",
       " 81,\n",
       " 212,\n",
       " 1,\n",
       " 166,\n",
       " 158,\n",
       " 19,\n",
       " 4,\n",
       " 1015,\n",
       " 576,\n",
       " 718,\n",
       " 239,\n",
       " 977,\n",
       " 851,\n",
       " 264,\n",
       " 814,\n",
       " 15,\n",
       " 718,\n",
       " 239,\n",
       " 242,\n",
       " 1569,\n",
       " 151,\n",
       " 1763,\n",
       " 931,\n",
       " 2,\n",
       " 33,\n",
       " 54,\n",
       " 230,\n",
       " 244,\n",
       " 1564,\n",
       " 358,\n",
       " 6,\n",
       " 10,\n",
       " 161,\n",
       " 143,\n",
       " 155,\n",
       " 41,\n",
       " 2,\n",
       " 172,\n",
       " 555,\n",
       " 3,\n",
       " 80,\n",
       " 1296,\n",
       " 271,\n",
       " 1609,\n",
       " 659,\n",
       " 100,\n",
       " 59,\n",
       " 1,\n",
       " 11,\n",
       " 59,\n",
       " 699,\n",
       " 1361,\n",
       " 2409,\n",
       " 1584,\n",
       " 56,\n",
       " 4,\n",
       " 339,\n",
       " 165,\n",
       " 8,\n",
       " 977,\n",
       " 851,\n",
       " 1,\n",
       " 1361,\n",
       " 2409,\n",
       " 1584,\n",
       " 5,\n",
       " 105,\n",
       " 70,\n",
       " 18,\n",
       " 105,\n",
       " 62,\n",
       " 6,\n",
       " 132,\n",
       " 744,\n",
       " 1533,\n",
       " 20,\n",
       " 10,\n",
       " 242,\n",
       " 1569,\n",
       " 1,\n",
       " 166,\n",
       " 158,\n",
       " 46,\n",
       " 165,\n",
       " 8,\n",
       " 493,\n",
       " 115,\n",
       " 18,\n",
       " 77,\n",
       " 62,\n",
       " 654,\n",
       " 1269,\n",
       " 257,\n",
       " 703,\n",
       " 470,\n",
       " 2,\n",
       " 422,\n",
       " 252,\n",
       " 212,\n",
       " 3,\n",
       " 244,\n",
       " 1564,\n",
       " 639,\n",
       " 845,\n",
       " 84,\n",
       " 1,\n",
       " 1361,\n",
       " 2409,\n",
       " 1584,\n",
       " 194,\n",
       " 165,\n",
       " 8,\n",
       " 33,\n",
       " 54,\n",
       " 37,\n",
       " 1808,\n",
       " 1758,\n",
       " 721,\n",
       " 1,\n",
       " 108,\n",
       " 21,\n",
       " 10,\n",
       " 324,\n",
       " 117,\n",
       " 220,\n",
       " 503,\n",
       " 1,\n",
       " 19,\n",
       " 173,\n",
       " 125,\n",
       " 96,\n",
       " 5,\n",
       " 219,\n",
       " 44,\n",
       " 1084,\n",
       " 1012,\n",
       " 961,\n",
       " 365,\n",
       " 1,\n",
       " 151,\n",
       " 242,\n",
       " 1569,\n",
       " 1464,\n",
       " 611,\n",
       " 121,\n",
       " 10,\n",
       " 100,\n",
       " 59,\n",
       " 333,\n",
       " 1434,\n",
       " 562,\n",
       " 977,\n",
       " 851,\n",
       " 3,\n",
       " 269,\n",
       " 60,\n",
       " 8,\n",
       " 10,\n",
       " 1361,\n",
       " 2409,\n",
       " 1584,\n",
       " 19,\n",
       " 22,\n",
       " 644,\n",
       " 139,\n",
       " 1,\n",
       " 166,\n",
       " 158,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 39,\n",
       " 1190,\n",
       " 11,\n",
       " 977,\n",
       " 851,\n",
       " 56,\n",
       " 336,\n",
       " 68,\n",
       " 170,\n",
       " 316,\n",
       " 1619,\n",
       " 1524,\n",
       " 1,\n",
       " 109,\n",
       " 41,\n",
       " 5,\n",
       " 747,\n",
       " 169,\n",
       " 157,\n",
       " 200,\n",
       " 40,\n",
       " 264,\n",
       " 1931,\n",
       " 80,\n",
       " 545,\n",
       " 37,\n",
       " 242,\n",
       " 1569,\n",
       " 1,\n",
       " 345,\n",
       " 50,\n",
       " 282,\n",
       " 283,\n",
       " 1040,\n",
       " 769,\n",
       " 200,\n",
       " 3,\n",
       " 80,\n",
       " 291,\n",
       " 589,\n",
       " 244,\n",
       " 200,\n",
       " 387,\n",
       " 1197,\n",
       " 2173,\n",
       " 6,\n",
       " 422,\n",
       " 252,\n",
       " 212,\n",
       " 11,\n",
       " 264,\n",
       " 814,\n",
       " 293,\n",
       " 610,\n",
       " 245,\n",
       " 1462,\n",
       " 725,\n",
       " 492,\n",
       " 2,\n",
       " 65,\n",
       " 228,\n",
       " 1,\n",
       " 46,\n",
       " 219,\n",
       " 6,\n",
       " 1609,\n",
       " 659,\n",
       " 2,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 54,\n",
       " 6,\n",
       " 231,\n",
       " 110,\n",
       " 981,\n",
       " 2629,\n",
       " 1,\n",
       " 23,\n",
       " 977,\n",
       " 851,\n",
       " 11,\n",
       " 9,\n",
       " 631,\n",
       " 3222,\n",
       " 4015,\n",
       " 244,\n",
       " 200,\n",
       " 40,\n",
       " 41,\n",
       " 483,\n",
       " 215,\n",
       " 111,\n",
       " 69,\n",
       " 1,\n",
       " 28,\n",
       " 40,\n",
       " 51,\n",
       " 9,\n",
       " 45,\n",
       " 333,\n",
       " 33,\n",
       " 19,\n",
       " 184,\n",
       " 2,\n",
       " 182,\n",
       " 162,\n",
       " 10,\n",
       " 3,\n",
       " 24,\n",
       " 4,\n",
       " 172,\n",
       " 152,\n",
       " 69,\n",
       " 13,\n",
       " 200,\n",
       " 127,\n",
       " 185,\n",
       " 3,\n",
       " 175,\n",
       " 132,\n",
       " 744,\n",
       " 32,\n",
       " 1609,\n",
       " 659,\n",
       " 1,\n",
       " 1190,\n",
       " 298,\n",
       " 4,\n",
       " 533,\n",
       " 1333,\n",
       " 546,\n",
       " 205,\n",
       " 16,\n",
       " 725,\n",
       " 244,\n",
       " 1,\n",
       " 23,\n",
       " 46,\n",
       " 2132,\n",
       " 10,\n",
       " 1,\n",
       " 28,\n",
       " 40,\n",
       " 531,\n",
       " 32,\n",
       " 986,\n",
       " 662,\n",
       " 1190,\n",
       " 56,\n",
       " 61,\n",
       " 32,\n",
       " 986,\n",
       " 662,\n",
       " 1,\n",
       " 6,\n",
       " 132,\n",
       " 744,\n",
       " 385,\n",
       " 130,\n",
       " 977,\n",
       " 851,\n",
       " 88,\n",
       " 230,\n",
       " 14,\n",
       " 1190,\n",
       " 305,\n",
       " 3011,\n",
       " 30,\n",
       " 10,\n",
       " 1,\n",
       " 165,\n",
       " 265,\n",
       " 32,\n",
       " 34,\n",
       " 1609,\n",
       " 659,\n",
       " 433,\n",
       " 1635,\n",
       " 32,\n",
       " 19,\n",
       " 187,\n",
       " 182,\n",
       " 162,\n",
       " 3,\n",
       " 24,\n",
       " 4,\n",
       " 172,\n",
       " 16,\n",
       " 725,\n",
       " 157,\n",
       " 200,\n",
       " 46,\n",
       " 39,\n",
       " 1190,\n",
       " 298,\n",
       " 2,\n",
       " 23,\n",
       " 808,\n",
       " 2026,\n",
       " 24,\n",
       " 8,\n",
       " 156,\n",
       " 9,\n",
       " 311,\n",
       " 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vector_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "maxlen=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "train_Y = kr.utils.to_categorical(label.fit_transform(train_label_list),num_classes=num_classes)\n",
    "test_Y = kr.utils.to_categorical(label.fit_transform(test_label_list),num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(train_vector_list,maxlen=600,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1056,  328,  610,  575,  580, 1175,  387, 1111,  579,    9, 1061,\n",
       "       1676,    0,  424,  327,  757,  656,  306,  667,  148,  995,  107,\n",
       "        587,  164,   58,  499,  134,  409,  600,  226,  259,   27,  123,\n",
       "         12,   12,   70,   55,   62,   87,  961,  154, 1429,   27,  123,\n",
       "         12,   12,   70,   83,   62,   85,  378,  365,    1,  327,  757,\n",
       "          6,  453,  460,  950,  100,   59,    1,    6,  976, 1253,   11,\n",
       "        169,  107,   36,   10,  977,  851,    3,  977,  851,  319,  920,\n",
       "         59,    1,  387, 1111,  286,  264,   10,  224,   98,    2,  569,\n",
       "        692,    1,  127,  185,  327,  757,  716,  153,  306,   41,    6,\n",
       "        148,  995,   27,  884,  667,   32,  107,  587,  164,    3,  816,\n",
       "        125,   39,  669, 1623,    2,   81,  212,   11,    1,   71,   59,\n",
       "         27,  884,  387, 1111,    2,  107,  587, 1041,  307,   31,  233,\n",
       "       1086,  157,    9,  107,  219,  327,  757,  580,  202,   10,   71,\n",
       "         59, 1285,  553,    2,  112,   35,    3,  387, 1111,   84,   38,\n",
       "         23,  143,  153,    1,  250,    5,   22,  580,  417,    2, 1177,\n",
       "        873,    1,  548,  417,    9,   41,  333,  130,   37,   42,    3,\n",
       "         28,   40,   31,   59,   35,  149,  254,   68, 2005,  171,    1,\n",
       "        149,  440,   11,  501,  128,    1,    9,   41,  333,  130,  193,\n",
       "        453,  328,  230, 1285,  553,    3,   24,  327,  757,   65,  453,\n",
       "         57,   81,  212,   88,    5,  507,   57,  443,  332,    1,  387,\n",
       "       1111,  272,   21,   61,  507,   57,  236,  274,   33,    6,  173,\n",
       "         22,   67,   94,   38,   23,   28,   40,    2,  488,  513,   30,\n",
       "        620,  828,    6,   61,  507,   57,    8,  236,  274,    1,  548,\n",
       "        417,  201,   66,   19,  385,  125,    2,  977,  851,    1,   66,\n",
       "        385,  125,   28,   40,   32, 1143,  324,  318,  574,  725,   27,\n",
       "         45,  311,  526,   19,   22,  236,  274,    3,   24,  732, 1150,\n",
       "        257,   30, 1169,  171,    6,  286,  264,  569,  692,    2,   27,\n",
       "        475,   88,  198,   32,   23, 1061, 1676,   24,   19,   22, 1247,\n",
       "          1,  143,  230,  236,  209,   97,  262,    5,  687, 1061, 1676,\n",
       "         27,    1,  387, 1111,  841,   10,   38,   23,  206,   19,   22,\n",
       "        236,  274,  342,  219,   28, 1061, 1676,    3,   28,    9, 1061,\n",
       "       1676,    1,   28,   40,  183,    5,    9,  631,  851,  627,    1,\n",
       "         28,   40,   35,  667,   32,  236,  274,    2, 1004,  528,    2,\n",
       "          3,   24,  387, 1111,  272,   21,    1,  327,  757,   61,  507,\n",
       "         57,    2,  107,  587,  275,  547,  716,  153,    9,  171, 1178,\n",
       "         38,   23,   28,   40,  306,   41,  115,  296,  107,  587,    1,\n",
       "         28,   40,    6,  653,   59,    2,   27,  475,    1,  306,   41,\n",
       "        667,   32,   45,  107,  587,    2,   43, 1427,    1,   28,   40,\n",
       "        306,   41,  667,   32,    4,  156,  222,   26,  484,  248,    3,\n",
       "         24,  212,  427,  642,  153,  606,  606,   72,  404,    1,  108,\n",
       "          5,  387, 1111,  127,  185,    1,   41,  663,  459,  311,  526,\n",
       "        157,  244,   33,   54,    2,  236,  274,   38,   23,  325,  851,\n",
       "         84,   66,    1,   19,    5,   22, 1223,  132,    2,  941,  292,\n",
       "          1,   96,    8,  105,   78,   57,   81,  212,    1,  108,    5,\n",
       "         28,   40,    9,   45, 1208,    6,   19,  159, 1087,  385,   57,\n",
       "         81,  212,   59,   84,    1,   28,   40,   96,    8,  105,    7,\n",
       "         57,   81,  212,   41,  254,    3,   28,   40,  306,   41,  663,\n",
       "        459,  311,  526,  157,  244,    2,  236,  274,    3,   24,   87,\n",
       "         58,  499,  134,  409,    0,  363,  189, 2063,    0,   37,   97,\n",
       "        961,  154, 1429,   85,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pad_sequences(test_vector_list,maxlen=600,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 128)          640000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 593, 256)          262400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 936,586\n",
      "Trainable params: 936,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "Embdding=model.add(layers.Embedding(5000,128,input_length=600))\n",
    "con=model.add(layers.Conv1D(filters=256,kernel_size=8))\n",
    "maxpool=model.add(layers.MaxPooling1D(593))\n",
    "flatten=model.add(layers.Flatten())\n",
    "dense1=model.add(layers.Dense(128, input_dim=100))  # 64是输出层的维度\n",
    "dropout=model.add(layers.Dropout(0.8))  # 控制需要断开的神经元比例，此处应该为0.2\n",
    "active1=model.add(layers.core.Activation('relu'))\n",
    "dense2=model.add(layers.Dense(10, input_shape=(600,128)))\n",
    "predict_y=model.add(layers.core.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "optimizer = optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 698s 14ms/step - loss: 0.7246 - acc: 0.7706 - val_loss: 0.2140 - val_acc: 0.9383\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 715s 14ms/step - loss: 0.2617 - acc: 0.9235 - val_loss: 0.1871 - val_acc: 0.9469\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 715s 14ms/step - loss: 0.1875 - acc: 0.9443 - val_loss: 0.1891 - val_acc: 0.9479\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 719s 14ms/step - loss: 0.1354 - acc: 0.9594 - val_loss: 0.1874 - val_acc: 0.9519\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 728s 15ms/step - loss: 0.1030 - acc: 0.9690 - val_loss: 0.2185 - val_acc: 0.9460\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 689s 14ms/step - loss: 0.0751 - acc: 0.9766 - val_loss: 0.2365 - val_acc: 0.9467\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 709s 14ms/step - loss: 0.0570 - acc: 0.9814 - val_loss: 0.2250 - val_acc: 0.9537\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 719s 14ms/step - loss: 0.0501 - acc: 0.9837 - val_loss: 0.2810 - val_acc: 0.9487\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 715s 14ms/step - loss: 0.0431 - acc: 0.9861 - val_loss: 0.2573 - val_acc: 0.9536\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 747s 15ms/step - loss: 0.0411 - acc: 0.9863 - val_loss: 0.2534 - val_acc: 0.9526\n",
      "50000/50000 [==============================] - 216s 4ms/step\n",
      "0.9988\n",
      "10000/10000 [==============================] - 47s 5ms/step\n",
      "0.9526\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,train_Y,batch_size=64,epochs=10,verbose=1,validation_data=(X_test,test_Y))\n",
    "loss_value, accuracy_value = model.evaluate(X_train,train_Y)\n",
    "print(accuracy_value)\n",
    "loss,accuracy = model.evaluate(X_test,test_Y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-52d09bb01d1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
