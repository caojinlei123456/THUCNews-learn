{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E://cnews/cnews.vocab.txt', encoding='utf8') as file:\n",
    "    vocabulary_list = [k.strip() for k in file.readlines()]\n",
    "#读取词表\n",
    "with open('E://cnews/cnews.train.txt', encoding='utf8') as file:\n",
    "    line_list = [k.strip() for k in file.readlines()]\n",
    "    #读取每行\n",
    "    train_label_list = [k.split()[0] for k in line_list]\n",
    "    #将标签依次取出\n",
    "    train_content_list = [k.split(maxsplit=1)[1] for k in line_list]\n",
    "    #将内容依次取出,此处注意split()选择最大分割次数为1,否则句子被打断.\n",
    "#同理读取test数据\n",
    "with open('E://cnews/cnews.test.txt', encoding='utf8') as file:\n",
    "    line_list = [k.strip() for k in file.readlines()]\n",
    "    test_label_list = [k.split()[0] for k in line_list]\n",
    "    test_content_list = [k.split(maxsplit=1)[1] for k in line_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_dict = dict(((b, a) for a, b in enumerate(vocabulary_list)))\n",
    "def content2vector(content_list):\n",
    "    content_vector_list = []\n",
    "    for content in content_list:\n",
    "        content_vector = []\n",
    "        for word in content:\n",
    "            if word in word2id_dict:\n",
    "                content_vector.append(word2id_dict[word])\n",
    "            else:\n",
    "                content_vector.append(word2id_dict['<PAD>'])\n",
    "        content_vector_list.append(content_vector)\n",
    "    return content_vector_list\n",
    "train_vector_list = content2vector(train_content_list)\n",
    "test_vector_list = content2vector(test_content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "num_classes=10\n",
    "maxlen=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "train_Y = kr.utils.to_categorical(label.fit_transform(train_label_list),num_classes=num_classes)\n",
    "test_Y = kr.utils.to_categorical(label.fit_transform(test_label_list),num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pad_sequences(train_vector_list,maxlen=600,truncating='post',padding='post') # 和原作者的不同\n",
    "test_X = pad_sequences(test_vector_list,maxlen=600,truncating='post',padding='post') # 和原作者不同 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 128)          640000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 593, 256)          262400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 936,586\n",
      "Trainable params: 936,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "Embdding=model.add(layers.Embedding(5000,128,input_length=600))\n",
    "con=model.add(layers.Conv1D(filters=256,kernel_size=8))\n",
    "maxpool=model.add(layers.MaxPooling1D(593))\n",
    "flatten=model.add(layers.Flatten())\n",
    "dense1=model.add(layers.Dense(128, input_dim=100))  # 64是输出层的维度\n",
    "dropout=model.add(layers.Dropout(0.2))  # 控制需要断开的神经元比例，此处应该为0.2\n",
    "active1=model.add(layers.core.Activation('relu'))\n",
    "dense2=model.add(layers.Dense(10, input_shape=(600,128)))\n",
    "predict_y=model.add(layers.core.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "optimizer = optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['categorical_accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:100 loss:0.5100 accuracy:0.8550\n",
      "step:200 loss:0.3632 accuracy:0.8850\n",
      "step:300 loss:0.1908 accuracy:0.9300\n",
      "step:400 loss:0.1505 accuracy:0.9650\n",
      "step:500 loss:0.1947 accuracy:0.9450\n",
      "step:600 loss:0.1246 accuracy:0.9700\n",
      "step:700 loss:0.1799 accuracy:0.9550\n",
      "step:800 loss:0.1554 accuracy:0.9600\n",
      "step:900 loss:0.1190 accuracy:0.9500\n",
      "step:1000 loss:0.1465 accuracy:0.9650\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(1000):\n",
    "    train_index = random.sample(list(range(len(train_Y))),k=64)\n",
    "    X = train_X[train_index]\n",
    "    Y = train_Y[train_index]\n",
    "    model.fit(X,Y,verbose=0)\n",
    "    step = i + 1 \n",
    "    if step % 100 == 0:\n",
    "        test_index = random.sample(list(range(len(test_Y))), k=200)\n",
    "        x = test_X[test_index]\n",
    "        y = test_Y[test_index]\n",
    "        loss_value, accuracy_value = model.evaluate(x,y,verbose=0)\n",
    "        print('step:%d loss:%.4f accuracy:%.4f' %(step, loss_value, accuracy_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model,to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
